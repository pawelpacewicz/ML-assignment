---
title: "Assignment on Practical Machine Learning"
author: "Pawe≈Ç Pacewicz"
date: "24 stycznia 2016"
output: html_document
---

# Initiation

```{r libraries, echo=FALSE, messages=FALSE}
library(caret)
#install.packages("randomForest")
library(randomForest)
library(rpart)
#install.packages("rpart.plot")
library(rpart.plot)
library(RColorBrewer)
#install.packages("rattle")
library(rattle)
library(dplyr)
library(lubridate)
```


```{r get data, cache=TRUE}
#rm(list=ls())
#HOME
#setwd("C:/Users/Silverbald/Dysk Google/EDU/Coursera/Data Science/8 Machine Learning/ML-assignment")
#WORK
#setwd("C:/Users/pawel.pacewicz/Dysk Google/EDU/Coursera/Data Science/8 Machine Learning/assignment")
#setwd("C:/Users/Silverbald/Dysk Google/EDU/Coursera/Data Science/8 Machine Learning/assignment")
training<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", na.strings=c("NA","#DIV/0!",""))
testing<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
#save.image(file="data.RData")
#load("data.RData")
```

```{r set seed}
set.seed(1234)
```

# Introduction

## Goal
Goal of this project is to predict the "classe" variable in the training set. "classe" describes manner in which participants did the exercise. There are 5 different fashions:

- exactly according to the specification (Class A) - correct execution of the excercise,
- throwing the elbows to the front (Class B) - incorrect execution of the excercise,
- lifting the dumbbell only halfway (Class C) - incorrect execution of the excercise,
- lowering the dumbbell only halfway (Class D) - incorrect execution of the excercise,
- and throwing the hips to the front (Class E) - incorrect execution of the excercise.

## Data

Data consisit of `r dim(training)[2]` columns
it was splited into 2 sets:

- training set: `r dim(training)[1]` records
- testing set: `r dim(testing)[1]` records

there are `r n_sensors<-length(colnames(select(training, contains("amplitude_pitch_")))); n_sensors` sensors located on:

- arm (columns contains "_arm")
- belt (columns contains "_belt")
- forearm (columns contains "_forearm")
- dumbbell (columns contains "_dumbbell")

each of those sensors is measuring `r n_meassured_values<-length(colnames(select(training, contains("_arm")))); n_meassured_values` values which are recorded in columns of our data. For example for sensor located on arm column names are following:
```{r, echo=FALSE}
colnames(select(training, contains("_arm")))
```
all combinations of sensor locations (`r n_sensors`) and measured values (`r n_meassured_values`) gives us `r n_sensors * n_meassured_values`. All columns in data is `r dim(training)[2]` so other columns are:
```{r, echo=FALSE}
colnames(select(training, -contains("_arm"), -contains("_belt"), -contains("_forearm"), -contains("_dumbbell")))
```


# Reproducibility

# How I built my model

I Build model with the following steps:

1. cleaning the data - removing data (columns) which does not affect results (or affect it slightly)
1. preparing sub-training and sub-testing sets
1. training algorithms (on sub-training data) - Decision Trees and Random Forest
1. making predictions (on sub-testing data)
1. comparing prediction results on both algorithms
1. using better algorithm to predict testing data

# cleaning the data

## removing columns with near zero variance

```{r near zero value}
nzv_training<-nearZeroVar(training, saveMetrics = TRUE)
training<-training[,!nzv_training$nzv]
testing<-testing[,!nzv_training$nzv]
```

## removing variables with high level of NAs (50%)

```{r high level NAs}
highLevelNAs<-sapply(training, function(x) {(sum(is.na(x))/nrow(training))>0.5})
training<-training[,!highLevelNAs]
testing<-testing[,!highLevelNAs]
```

## removing data not related to measurements

this is data located in 1st 6 columns:

```{r}
colnames(training[,1:6])
```

```{r predictors not related to measuremenrts}
training<-training[,-(1:6)]
testing<-testing[,-(1:6)]
```

## removing highly correlated predictors

```{r highly correlated}
highlyCor<-findCorrelation(cor(training[,-53]))
training<-training[,-highlyCor]
testing<-testing[,-highlyCor]
```

# preparing sub-training and sub-testing sets

Training data will be split into 2 sub-sets:

1. SubTraining (70%)
1. SubTesting (30%)

```{r create Data Partition}
inTrain <- createDataPartition(y=training$classe, p=0.7, list=FALSE)
subTraining <- training[inTrain, ]
subTesting <- training[-inTrain, ]
```

# Training and prediction

2 training alorithms will be used:

1. Decision Tree
1. Random Forest

for both of them the same trainControl patrameters will be used.

Here is definition of Cross Validation usage with 8 folds. It will be applied for both training alghoritms.

```{r train Control}
tc <- trainControl(method = "cv", number = 8, verboseIter=FALSE , preProcOptions="pca", allowParallel=TRUE)
```

## Decision Tree

```{r train Decision Tree, cache=TRUE}
modFit_DT<-train(classe~., data=subTraining, method="rpart", trControl=tc)
```

## Random Forest

```{r train Random Forest, cache=TRUE}
modFit_RF<-train(classe~., data=subTraining, method="rf", trControl=tc)
```

# results

## ptredictions

for both algorithms prediction results are prepared:

```{r predict}
predict_DT<-predict(modFit_DT, newdata = subTesting[,-46])
predict_RF<-predict(modFit_RF, newdata = subTesting[,-46])
```

## comparition

below are results for both algorithms

```{r confusionMatrix}
cf_DT<-confusionMatrix(predict_DT,subTesting$classe)
cf_DT

cf_RF<-confusionMatrix(predict_RF,subTesting$classe)
cf_RF
```

we can se clearly that Random Forest accuracy is very high `r cf_DT$overall[[1]]` and much better than Decision Tree accuracy `r cf_RF$overall[[1]]`. Due to that we will use Random Forest model to make final prediction on testing data

```{r results on final data set}
results<-predict(modFit_RF, newdata = testing[,-46])
results
```

# sources

Source of data:
http://groupware.les.inf.puc-rio.br/har#ixzz3yqY8niSY

## DLA dataset and literature review

Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements. Proceedings of 21st Brazilian Symposium on Artificial Intelligence. Advances in Artificial Intelligence - SBIA 2012. In: Lecture Notes in Computer Science. , pp. 52-61. Curitiba, PR: Springer Berlin / Heidelberg, 2012. ISBN 978-3-642-34458-9. DOI: 10.1007/978-3-642-34459-6_6. 
Cited by 2 (Google Scholar) 

## WLE dataset

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013. 


====

TODO:

The goal of your project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. You may use any of the other variables to predict with.
You should create a report describing:

 - how you built your model,
 - how you used cross validation,
 - what you think the expected out of sample error is, and
 - why you made the choices you did.
 
You will also use your prediction model to predict 20 different test cases.


Peer Review Portion

Your submission for the Peer Review portion should consist of a link to a Github repo with your R markdown and compiled HTML file describing your analysis. Please constrain the text of the writeup to < 2000 words and the number of figures to be less than 5. It will make it easier for the graders if you submit a repo with a gh-pages branch so the HTML page can be viewed online (and you always want to make it easy on graders :-).

Course Project Prediction Quiz Portion

Apply your machine learning algorithm to the 20 test cases available in the test data above and submit your predictions in appropriate format to the Course Project Prediction Quiz for automated grading.

Reproducibility

Due to security concerns with the exchange of R code, your code will not be run during the evaluation by your classmates. Please be sure that if they download the repo, they will be able to view the compiled HTML version of your analysis.

http://groupware.les.inf.puc-rio.br/har

